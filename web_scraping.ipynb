{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5fiwMvf3iK9xHo6ljoMkZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabordun/web_scraping/blob/master/web_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivafqztuo-Os",
        "colab_type": "code",
        "outputId": "37ef22bc-6fde-499d-8313-bc96e2e730af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#import packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import time\n",
        "\n",
        "#import requests\n",
        "\n",
        "from urllib import request\n",
        "import requests\n",
        "\n",
        "#finding sources\n",
        "\n",
        "\n",
        "url = 'http://www.ebizmba.com/articles/news-websites'\n",
        "\n",
        "def getAllUrl(url):\n",
        "    try:\n",
        "        page = request.urlopen(url).read()\n",
        "    except:\n",
        "        return []\n",
        "    urlList = []\n",
        "    try:\n",
        "        soup = BeautifulSoup(page)\n",
        "        soup.prettify()\n",
        "        for anchor in soup.findAll('a', href=True):\n",
        "            if not 'http://' in anchor['href']:\n",
        "                if urlparse.urljoin(url, anchor['href']) not in urlList:\n",
        "                    urlList.append(urlparse.urljoin(url, anchor['href']))\n",
        "            else:\n",
        "                if anchor['href'] not in urlList:\n",
        "                    urlList.append(anchor['href'])\n",
        "\n",
        "        length = len(urlList)\n",
        "\n",
        "        return urlList\n",
        "    except request.HTTPError as e:\n",
        "        print(e)\n",
        "\n",
        "print(getAllUrl(url))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['http://www.ebizmba.com/', 'http://www.ebizmba.com/directory#admin', 'http://www.ebizmba.com/directory#design', 'http://www.ebizmba.com/directory#marketing', 'http://www.ebizmba.com/directory#ecommerce', 'http://www.ebizmba.com/directory', 'http://www.ebizmba.com/directory#media', 'http://www.ebizmba.com/directory#research', \"javascript:bookmarksite('eBizMBA | The eBusiness Knowledgebase', 'http://www.ebizmba.com')\", 'http://www.ebizmba.com/terms', 'http://www.ebizmba.com/privacy', 'http://news.yahoo.com', 'http://siteanalytics.compete.com/news.yahoo.com', 'http://quantcast.com/news.yahoo.com', 'http://www.alexa.com/siteinfo/news.yahoo.com/', 'http://news.google.com', 'http://siteanalytics.compete.com/news.google.com', 'http://quantcast.com/news.google.com', 'http://www.alexa.com/siteinfo/news.google.com/', 'http://www.huffingtonpost.com', 'http://siteanalytics.compete.com/huffingtonpost.com', 'http://quantcast.com/huffingtonpost.com', 'http://www.alexa.com/siteinfo/huffingtonpost.com/', 'http://www.cnn.com', 'http://siteanalytics.compete.com/cnn.com', 'http://quantcast.com/cnn.com', 'http://www.alexa.com/siteinfo/cnn.com/', 'http://www.nytimes.com', 'http://siteanalytics.compete.com/nytimes.com', 'http://quantcast.com/nytimes.com', 'http://www.alexa.com/siteinfo/nytimes.com/', 'http://www.foxnews.com', 'http://siteanalytics.compete.com/foxnews.com', 'http://quantcast.com/foxnews.com', 'http://www.alexa.com/siteinfo/foxnews.com/', 'http://www.nbcnews.com', 'http://siteanalytics.compete.com/nbcnews.com', 'http://quantcast.com/nbcnews.com', 'http://www.alexa.com/siteinfo/nbcnews.com/', 'http://www.dailymail.co.uk', 'http://siteanalytics.compete.com/dailymail.co.uk', 'http://quantcast.com/dailymail.co.uk', 'http://www.alexa.com/siteinfo/dailymail.co.uk', 'http://www.washingtonpost.com', 'http://siteanalytics.compete.com/washingtonpost.com', 'http://quantcast.com/washingtonpost.com', 'http://www.alexa.com/siteinfo/washingtonpost.com/', 'http://www.theguardian.com', 'http://siteanalytics.compete.com/theguardian.com', 'http://quantcast.com/theguardian.com', 'http://www.alexa.com/siteinfo/theguardian.com/', 'http://www.wsj.com', 'http://siteanalytics.compete.com/wsj.com', 'http://quantcast.com/wsj.com', 'http://www.alexa.com/siteinfo/wsj.com/', 'http://www.abcnews.go.com', 'http://siteanalytics.compete.com/abcnews.go.com', 'http://quantcast.com/abcnews.go.com', 'http://www.alexa.com/siteinfo/abcnews.go.com/', 'http://news.bbc.co.uk', 'http://siteanalytics.compete.com/news.bbc.co.uk', 'http://quantcast.com/news.bbc.co.uk', 'http://www.alexa.com/siteinfo/news.bbc.co.uk/', 'http://www.usatoday.com', 'http://siteanalytics.compete.com/usatoday.com', 'http://quantcast.com/usatoday.com', 'http://www.alexa.com/siteinfo/usatoday.com/', 'http://www.latimes.com', 'http://siteanalytics.compete.com/latimes.com', 'http://quantcast.com/latimes.com', 'http://www.alexa.com/siteinfo/latimes.com/', 'http://www.ebizmba.com/articles/best-flash-sites', 'http://www.ebizmba.com/articles/best-html5-websites', 'http://www.ebizmba.com/articles/blogs', 'http://www.ebizmba.com/articles/business-websites', 'http://www.ebizmba.com/articles/car-websites', 'http://www.ebizmba.com/articles/coupon-websites', 'http://www.ebizmba.com/articles/dating-websites', 'http://www.ebizmba.com/articles/design-websites', 'http://www.ebizmba.com/articles/ebusiness-websites', 'http://www.ebizmba.com/articles/file-sharing-websites', 'http://www.ebizmba.com/articles/funny-websites', 'http://www.ebizmba.com/articles/gadget-websites', 'http://www.ebizmba.com/articles/game-websites', 'http://www.ebizmba.com/articles/gossip-websites', 'http://www.ebizmba.com/articles/health-websites', 'http://www.ebizmba.com/articles/job-websites', 'http://www.ebizmba.com/articles/kids-websites', 'http://www.ebizmba.com/articles/media-websites', 'http://www.ebizmba.com/articles/most-popular-websites', 'http://www.ebizmba.com/articles/movie-websites', 'http://www.ebizmba.com/articles/music-websites', 'http://www.ebizmba.com/articles/news-websites', 'http://www.ebizmba.com/articles/people-search', 'http://www.ebizmba.com/articles/personal-finance-websites', 'http://www.ebizmba.com/articles/photo-sharing-sites', 'http://www.ebizmba.com/articles/political-websites', 'http://www.ebizmba.com/articles/real-estate-websites', 'http://www.ebizmba.com/articles/recipe-websites', 'http://www.ebizmba.com/articles/reference-websites', 'http://www.ebizmba.com/articles/science-websites', 'http://www.ebizmba.com/articles/search-engines', 'http://www.ebizmba.com/articles/seo-websites', 'http://www.ebizmba.com/articles/shopping-websites', 'http://www.ebizmba.com/articles/social-bookmarking-websites', 'http://www.ebizmba.com/articles/social-networking-websites', 'http://www.ebizmba.com/articles/sports-websites', 'http://www.ebizmba.com/articles/travel-websites', 'http://www.ebizmba.com/articles/video-game-websites', 'http://www.ebizmba.com/articles/video-websites', 'http://www.ebizmba.com/articles/viral-sites', 'http://www.ebizmba.com/articles/web-2.0-websites', 'http://www.ebizmba.com/articles/web-hosting', 'http://www.ebizmba.com/company', 'http://www.ebizmba.com/contact']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t60DWdLQpTfg",
        "colab_type": "code",
        "outputId": "8d9f4740-63bb-4aa7-fa00-8717deb820c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# run counter\n",
        "\n",
        "for url in getAllUrl(url):\n",
        "  try: \n",
        "   basic=requests.get(url).text\n",
        "   soup=BeautifulSoup(basic, 'html.parser')\n",
        "  except:\n",
        "   pass\n",
        "\n",
        "  #b = soup.prettify()\n",
        "  #print(b)\n",
        "\n",
        "  keywords={'corona','Corona','coronavirus','corona virus','Corona Virus', 'Coronavirus'}\n",
        "\n",
        "  for x in keywords:\n",
        "   x = soup(text=re.compile('x'))\n",
        "   counter = 0\n",
        "   for item in x:\n",
        "    counter += 1\n",
        "  \n",
        "  print(counter)\n",
        "  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n",
            "42\n",
            "42\n",
            "42\n",
            "42\n",
            "42\n",
            "42\n",
            "42\n",
            "42\n",
            "7\n",
            "10\n",
            "128\n",
            "0\n",
            "1\n",
            "71\n",
            "67\n",
            "0\n",
            "1\n",
            "71\n",
            "2\n",
            "0\n",
            "1\n",
            "71\n",
            "24\n",
            "0\n",
            "1\n",
            "73\n",
            "50\n",
            "0\n",
            "1\n",
            "72\n",
            "84\n",
            "0\n",
            "1\n",
            "85\n",
            "26\n",
            "0\n",
            "1\n",
            "81\n",
            "188\n",
            "0\n",
            "1\n",
            "73\n",
            "57\n",
            "0\n",
            "1\n",
            "79\n",
            "54\n",
            "0\n",
            "1\n",
            "73\n",
            "11\n",
            "0\n",
            "1\n",
            "73\n",
            "32\n",
            "0\n",
            "1\n",
            "78\n",
            "104\n",
            "0\n",
            "1\n",
            "69\n",
            "18\n",
            "0\n",
            "1\n",
            "75\n",
            "1\n",
            "0\n",
            "1\n",
            "78\n",
            "11\n",
            "13\n",
            "23\n",
            "23\n",
            "25\n",
            "23\n",
            "23\n",
            "24\n",
            "24\n",
            "25\n",
            "23\n",
            "23\n",
            "23\n",
            "23\n",
            "24\n",
            "23\n",
            "23\n",
            "23\n",
            "23\n",
            "25\n",
            "23\n",
            "24\n",
            "23\n",
            "23\n",
            "23\n",
            "24\n",
            "24\n",
            "23\n",
            "24\n",
            "23\n",
            "26\n",
            "24\n",
            "24\n",
            "23\n",
            "7\n",
            "24\n",
            "24\n",
            "23\n",
            "24\n",
            "23\n",
            "22\n",
            "16\n",
            "3\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqI4wkyB9OMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_urls = ['https://welt.de',\n",
        "             'https://nytimes.com',\n",
        "             'https://theguardian.com',\n",
        "             'https://lefigaro.fr',\n",
        "             'https://elpais.com']\n",
        "\n",
        "for url in seed_urls:\n",
        "  basic=requests.get(url).text\n",
        "  soup=BeautifulSoup(basic, 'html.parser')\n",
        "\n",
        "  #b = soup.prettify()\n",
        "  #print(b)\n",
        "\n",
        "  keywords={'corona','Corona','coronavirus','corona virus','Corona Virus', 'Coronavirus'}\n",
        "\n",
        "  for x in keywords:\n",
        "   x = soup(text=re.compile('x'))\n",
        "   rowcounter = 0\n",
        "   for item in x:\n",
        "    rowcounter += 1\n",
        "  \n",
        "  y = soup.find_all('a')\n",
        "  colcounter = 0\n",
        "  for item in y:\n",
        "    colcounter += 1\n",
        "\n",
        "  print(rowcounter)\n",
        "  print(colcounter)\n",
        "\n",
        "  result = []\n",
        "  for i in range(0,colcounter):\n",
        "    a=y[i].get_text(\"title\").replace(\"title\",\" \").replace(\"\\n\",\" \")\n",
        "    result.append(a)\n",
        " \n",
        "  df = pd.DataFrame(data = result)\n",
        "  print(df)\n",
        "\n",
        "#df.to_csv(\"formula1.csv\")\n",
        "#uploaded = drive.CreateFile({'title': 'formula1.csv'})\n",
        "#uploaded.SetContentFile(\"formula1.csv\")\n",
        "#uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}